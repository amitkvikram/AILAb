{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question3: MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook has a vectorized implementation. \n",
    "> **After vectorization time reduced from 7minutes/iteration to 10 seconds/iteration if size = (20, 10, 10).**<br/>\n",
    "> **After vectorization time reduced from 6seconds/iteration to 0.44 second/iteration if size = (10, 5, 5).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson(lambda1, n):\n",
    "    return (np.power(lambda1, n)/np.math.factorial(n))*(np.exp(-lambda1))\n",
    "\n",
    "##########CONSTANTS###########\n",
    "requestLambda = [3, 2, 2]\n",
    "returnLambda = [3, 1, 1]\n",
    "\n",
    "#Number of maximum cars allowed at loc1, loc2, loc3\n",
    "ml1, ml2, ml3 = 20, 10, 10\n",
    "\n",
    "gamma = 0.9\n",
    "numIter = 10\n",
    "tol = 0.01\n",
    "Size = (ml1, ml2, ml3)\n",
    "\n",
    "n1 = np.arange(ml1)\n",
    "n2 = np.arange(ml2)\n",
    "n3 = np.arange(ml3)\n",
    "n4 = np.arange(-5, 6)\n",
    "#=============================#\n",
    "\n",
    "#================PreCalculations of Probability and Rewards============#\n",
    "JointProbLocation1 = np.ones((ml1, ml1))*0\n",
    "JointProbLocation2 = np.ones((ml2, ml2))*0\n",
    "JointProbLocation3 = np.ones((ml3, ml3))*0\n",
    "JointRewardLocation1 = np.ones((ml1, ml1))*0\n",
    "JointRewardLocation2 = np.ones((ml2, ml2))*0\n",
    "JointRewardLocation3 = np.ones((ml3, ml3))*0\n",
    "\n",
    "ProbRequestLocation1 = np.asarray([poisson(requestLambda[0], i) for i in range(ml1)])\n",
    "ProbRequestLocation2 = np.asarray([poisson(requestLambda[1], i) for i in range(ml2)])\n",
    "ProbRequestLocation3 = np.asarray([poisson(requestLambda[2], i) for i in range(ml3)])\n",
    "\n",
    "RewardRequestLocation1 = np.asarray([poisson(requestLambda[0], i)*i*10 for i in range(ml1)])\n",
    "RewardRequestLocation2 = np.asarray([poisson(requestLambda[1], i)*i*10 for i in range(ml2)])\n",
    "RewardRequestLocation3 = np.asarray([poisson(requestLambda[2], i)*i*10 for i in range(ml3)])\n",
    "\n",
    "ProbReturnLocation1 = np.asarray([poisson(returnLambda[0], i) for i in range(ml1)])\n",
    "ProbReturnLocation2 = np.asarray([poisson(returnLambda[1], i) for i in range(ml2)])\n",
    "ProbReturnLocation3 = np.asarray([poisson(returnLambda[2], i) for i in range(ml3)])\n",
    "\n",
    "\n",
    "for (currState, nextState) in itertools.product(n1, n1):  \n",
    "    for request, ret in itertools.product(n1, n1):\n",
    "        if(request > currState or currState-request+ret != nextState):\n",
    "            continue\n",
    "        JointProbLocation1[currState, nextState] += (ProbRequestLocation1[request]\n",
    "                            *ProbReturnLocation1[ret])\n",
    "        JointRewardLocation1[currState, nextState] += (ProbRequestLocation1[request]\n",
    "                            *ProbReturnLocation1[ret])*request*10\n",
    "            \n",
    "for (currState, nextState) in itertools.product(n2, n2):  \n",
    "    for request, ret in itertools.product(n2, n2):\n",
    "        if(request > currState or currState-request+ret != nextState):\n",
    "            continue\n",
    "        JointProbLocation2[currState, nextState] += (ProbRequestLocation2[request]\n",
    "                            *ProbReturnLocation2[ret])\n",
    "        JointRewardLocation2[currState, nextState] += (ProbRequestLocation2[request]\n",
    "                            *ProbReturnLocation2[ret])*request*10\n",
    "\n",
    "for (currState, nextState) in itertools.product(n3, n3):  \n",
    "    for request, ret in itertools.product(n3, n3):\n",
    "        if(request > currState or currState-request+ret != nextState):\n",
    "            continue\n",
    "        JointProbLocation3[currState, nextState] += (ProbRequestLocation3[request]\n",
    "                            *ProbReturnLocation3[ret])\n",
    "        JointRewardLocation3[currState, nextState] += (ProbRequestLocation3[request]\n",
    "                            *ProbReturnLocation3[ret])*request*10\n",
    "#=========================_________________________========================#\n",
    "        \n",
    "def normInfinity(currValue, optimalValue):\n",
    "    maxDiff = np.max(np.abs(currValue - optimalValue))\n",
    "    return maxDiff\n",
    "        \n",
    "\n",
    "def isValidState(car1, car2, car3):\n",
    "     return car1 >= 0 and car2 >=0 and car3 >=0 and car1 <ml1 and car2 < ml2 and car3 < ml3\n",
    "\n",
    "def getCost(mv1, mv2, mv3):\n",
    "    cost = np.abs(mv1)*2\n",
    "    return cost\n",
    "\n",
    "MOVES = []\n",
    "for mv1, mv2, mv3 in itertools.product(n4, n4, n4):\n",
    "    if(mv1 + mv2 + mv3 != 0):\n",
    "        continue\n",
    "    MOVES.append((mv1, mv2, mv3))\n",
    "\n",
    "\n",
    "#================================ Value Iteration ===========================#\n",
    "def ValueIteration(V, Policy):\n",
    "    for iter1 in (range(numIter)):\n",
    "        oldV = V.copy()\n",
    "        print(\"iter: \", iter1)\n",
    "        a = time.time()\n",
    "        #State value\n",
    "        for i, j, k in itertools.product(n1, n2, n3):\n",
    "#             print(i, j, k)\n",
    "            maxReward = -10000.0\n",
    "            for (mv1, mv2, mv3) in MOVES:\n",
    "#                 print(\"move1 = \", mv1, mv2, mv3)\n",
    "                reward = 0.0\n",
    "                car1 = i + mv1\n",
    "                car2 = j + mv2\n",
    "                car3 = k + mv3\n",
    "#                 print(i, j, k, car1, car2, car3)\n",
    "                \n",
    "                if(not isValidState(car1, car2, car3)):\n",
    "                    continue\n",
    "                \n",
    "                reward-=getCost(mv1, mv2, mv3)\n",
    "                \n",
    "                p1_sum = JointProbLocation1[car1, :]   #(10, )\n",
    "                p2_sum = JointProbLocation2[car2, :]   #(5, )\n",
    "                p3_sum = JointProbLocation3[car3, :]   #(5, )\n",
    "                r1_sum = JointRewardLocation1[car1, :].reshape(ml1, 1)  #(10, 1)\n",
    "                r2_sum = JointRewardLocation2[car2, :].reshape(ml2, 1)   #(5, 1)\n",
    "                r3_sum = JointRewardLocation3[car3, :].reshape(ml3, 1)    #(5, 1)\n",
    "                \n",
    "                p1p2_sum = np.dot(p1_sum.reshape(ml1, 1), p2_sum.reshape(1, ml2))  #(ml1, ml2)\n",
    "                p1p3_sum = np.dot(p1_sum.reshape(ml1, 1), p3_sum.reshape(1, ml3))  #(ml1, ml3)\n",
    "                p2p3_sum = np.dot(p2_sum.reshape(ml2, 1), p3_sum.reshape(1, ml3))  #(ml2, ml3)\n",
    "        \n",
    "                #========immediate Reward ======================#\n",
    "                r3p1p2 = np.sum(np.dot(np.tile(r3_sum, (1, ml1)), p1p2_sum))\n",
    "                r2p1p3 = np.sum(np.dot(np.tile(r2_sum, (1, ml1)), p1p3_sum))\n",
    "                r1p2p3 = np.sum(np.dot(np.tile(r1_sum, (1, ml2)), p2p3_sum))\n",
    "                \n",
    "                immediateReward = r3p1p2 + r2p1p3 + r1p2p3\n",
    "                #==================================================#\n",
    "                \n",
    "                #============Value from next State=================#\n",
    "                temp = np.tile(p2p3_sum, (ml1, 1, 1))\n",
    "                futureReward = np.multiply(temp, oldV)\n",
    "                temp1 = np.tile(p1_sum.reshape(ml1, 1, 1), (1, ml2, ml3))\n",
    "                futureReward = np.sum(np.multiply(futureReward, temp1))\n",
    "                #==================================================#\n",
    "                \n",
    "                reward += immediateReward+ gamma*futureReward\n",
    "                if(reward > maxReward):\n",
    "                    maxReward = reward\n",
    "                    Policy[i, j, k] = np.array([mv1, mv2, mv3])\n",
    "            V[i, j, k] = maxReward \n",
    "\n",
    "        if(normInfinity(V, oldV) <= 0.1):\n",
    "            print(\"Converged in {} iteration\".format(iter1 + 2))\n",
    "            break\n",
    "        print(\"Time for 1 iter = \",time.time() - a)\n",
    "    return V, Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0\n",
      "Time for 1 iter =  3350.737420797348\n",
      "iter:  1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "Size = (ml1, ml2, ml3)\n",
    "Value = np.zeros(Size)\n",
    "Policy = np.zeros(Size + tuple([3]))\n",
    "a = time.time()\n",
    "V, P = ValueIteration(Value, Policy)\n",
    "print(\"Time Taken = \",time.time() - a)\n",
    "np.savetxt(\"Value2.txt\", np.ravel(V).reshape(ml1*ml2, ml3), fmt = \"%.2f\", header = 'values')\n",
    "np.savetxt(\"Policy1.txt\", np.ravel(P).reshape(ml1*ml2*ml3, 3), fmt = \"%i\")\n",
    "print(\"Value2.txt Saved\")\n",
    "print(\"Policy2.txt Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-903d3228b74b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mn3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def poisson(lambda1, n):\n",
    "    return (np.power(lambda1, n)/np.math.factorial(n))*(np.exp(-lambda1))\n",
    "\n",
    "##########CONSTANTS###########\n",
    "requestLambda = [3, 2, 2]\n",
    "returnLambda = [3, 1, 1]\n",
    "\n",
    "#Number of maximum cars allowed at loc1, loc2, loc3\n",
    "ml1, ml2, ml3 = 20, 10, 10\n",
    "\n",
    "gamma = 0.9\n",
    "numIter = 10\n",
    "tol = 0.01\n",
    "Size = (ml1, ml2, ml3)\n",
    "\n",
    "n1 = np.arange(ml1)\n",
    "n2 = np.arange(ml2)\n",
    "n3 = np.arange(ml3)\n",
    "n4 = np.arange(-5, 6)\n",
    "#=============================#\n",
    "\n",
    "#================PreCalculations of Probability and Rewards============#\n",
    "JointProbLocation1 = np.ones((ml1, ml1))*0\n",
    "JointProbLocation2 = np.ones((ml2, ml2))*0\n",
    "JointProbLocation3 = np.ones((ml3, ml3))*0\n",
    "JointRewardLocation1 = np.ones((ml1, ml1))*0\n",
    "JointRewardLocation2 = np.ones((ml2, ml2))*0\n",
    "JointRewardLocation3 = np.ones((ml3, ml3))*0\n",
    "\n",
    "ProbRequestLocation1 = np.asarray([poisson(requestLambda[0], i) for i in range(ml1)])\n",
    "ProbRequestLocation2 = np.asarray([poisson(requestLambda[1], i) for i in range(ml2)])\n",
    "ProbRequestLocation3 = np.asarray([poisson(requestLambda[2], i) for i in range(ml3)])\n",
    "\n",
    "RewardRequestLocation1 = np.asarray([poisson(requestLambda[0], i)*i*10 for i in range(ml1)])\n",
    "RewardRequestLocation2 = np.asarray([poisson(requestLambda[1], i)*i*10 for i in range(ml2)])\n",
    "RewardRequestLocation3 = np.asarray([poisson(requestLambda[2], i)*i*10 for i in range(ml3)])\n",
    "\n",
    "ProbReturnLocation1 = np.asarray([poisson(returnLambda[0], i) for i in range(ml1)])\n",
    "ProbReturnLocation2 = np.asarray([poisson(returnLambda[1], i) for i in range(ml2)])\n",
    "ProbReturnLocation3 = np.asarray([poisson(returnLambda[2], i) for i in range(ml3)])\n",
    "\n",
    "\n",
    "for (currState, nextState) in itertools.product(n1, n1):  \n",
    "    for request, ret in itertools.product(n1, n1):\n",
    "        if(request > currState or currState-request+ret != nextState):\n",
    "            continue\n",
    "        JointProbLocation1[currState, nextState] += (ProbRequestLocation1[request]\n",
    "                            *ProbReturnLocation1[ret])\n",
    "        JointRewardLocation1[currState, nextState] += (ProbRequestLocation1[request]\n",
    "                            *ProbReturnLocation1[ret])*request*10\n",
    "            \n",
    "for (currState, nextState) in itertools.product(n2, n2):  \n",
    "    for request, ret in itertools.product(n2, n2):\n",
    "        if(request > currState or currState-request+ret != nextState):\n",
    "            continue\n",
    "        JointProbLocation2[currState, nextState] += (ProbRequestLocation2[request]\n",
    "                            *ProbReturnLocation2[ret])\n",
    "        JointRewardLocation2[currState, nextState] += (ProbRequestLocation2[request]\n",
    "                            *ProbReturnLocation2[ret])*request*10\n",
    "\n",
    "for (currState, nextState) in itertools.product(n3, n3):  \n",
    "    for request, ret in itertools.product(n3, n3):\n",
    "        if(request > currState or currState-request+ret != nextState):\n",
    "            continue\n",
    "        JointProbLocation3[currState, nextState] += (ProbRequestLocation3[request]\n",
    "                            *ProbReturnLocation3[ret])\n",
    "        JointRewardLocation3[currState, nextState] += (ProbRequestLocation3[request]\n",
    "                            *ProbReturnLocation3[ret])*request*10\n",
    "#=========================_________________________========================#\n",
    "        \n",
    "def normInfinity(currValue, optimalValue):\n",
    "    maxDiff = np.max(np.abs(currValue - optimalValue))\n",
    "    return maxDiff\n",
    "        \n",
    "\n",
    "def isValidState(car1, car2, car3):\n",
    "     return car1 >= 0 and car2 >=0 and car3 >=0 and car1 <ml1 and car2 < ml2 and car3 < ml3\n",
    "\n",
    "def getCost(mv1, mv2, mv3):\n",
    "    cost = np.abs(mv1)*2\n",
    "    return cost\n",
    "\n",
    "MOVES = []\n",
    "for mv1, mv2, mv3 in itertools.product(n4, n4, n4):\n",
    "    if(mv1 + mv2 + mv3 != 0):\n",
    "        continue\n",
    "    MOVES.append((mv1, mv2, mv3))\n",
    "\n",
    "\n",
    "#================================ Value Iteration ===========================#\n",
    "def ValueIteration(V, Policy):\n",
    "    for iter1 in (range(numIter)):\n",
    "        oldV = V.copy()\n",
    "        print(\"iter: \", iter1)\n",
    "        a = time.time()\n",
    "        #State value\n",
    "        for i, j, k in itertools.product(n1, n2, n3):\n",
    "#             print(i, j, k)\n",
    "            maxReward = -10000.0\n",
    "            for (mv1, mv2, mv3) in MOVES:\n",
    "#                 print(\"move1 = \", mv1, mv2, mv3)\n",
    "                reward = 0.0\n",
    "                car1 = i + mv1\n",
    "                car2 = j + mv2\n",
    "                car3 = k + mv3\n",
    "#                 print(i, j, k, car1, car2, car3)\n",
    "                \n",
    "                if(not isValidState(car1, car2, car3)):\n",
    "                    continue\n",
    "                \n",
    "                reward-=getCost(mv1, mv2, mv3)\n",
    "                \n",
    "                p1_sum = JointProbLocation1[car1, :]   #(10, )\n",
    "                p2_sum = JointProbLocation2[car2, :]   #(5, )\n",
    "                p3_sum = JointProbLocation3[car3, :]   #(5, )\n",
    "                r1_sum = JointRewardLocation1[car1, :].reshape(ml1, 1)  #(10, 1)\n",
    "                r2_sum = JointRewardLocation2[car2, :].reshape(ml2, 1)   #(5, 1)\n",
    "                r3_sum = JointRewardLocation3[car3, :].reshape(ml3, 1)    #(5, 1)\n",
    "                \n",
    "                p1p2_sum = np.dot(p1_sum.reshape(ml1, 1), p2_sum.reshape(1, ml2))  #(ml1, ml2)\n",
    "                p1p3_sum = np.dot(p1_sum.reshape(ml1, 1), p3_sum.reshape(1, ml3))  #(ml1, ml3)\n",
    "                p2p3_sum = np.dot(p2_sum.reshape(ml2, 1), p3_sum.reshape(1, ml3))  #(ml2, ml3)\n",
    "        \n",
    "                #========immediate Reward ======================#\n",
    "                r3p1p2 = np.sum(np.dot(np.tile(r3_sum, (1, ml1)), p1p2_sum))\n",
    "                r2p1p3 = np.sum(np.dot(np.tile(r2_sum, (1, ml1)), p1p3_sum))\n",
    "                r1p2p3 = np.sum(np.dot(np.tile(r1_sum, (1, ml2)), p2p3_sum))\n",
    "                \n",
    "                immediateReward = r3p1p2 + r2p1p3 + r1p2p3\n",
    "                #==================================================#\n",
    "                \n",
    "                #============Value from next State=================#\n",
    "                temp = np.tile(p2p3_sum, (ml1, 1, 1))\n",
    "                futureReward = np.multiply(temp, oldV)\n",
    "                temp1 = np.tile(p1_sum.reshape(ml1, 1, 1), (1, ml2, ml3))\n",
    "                futureReward = np.sum(np.multiply(futureReward, temp1))\n",
    "                #==================================================#\n",
    "                \n",
    "                reward += immediateReward+ gamma*futureReward\n",
    "                if(reward > maxReward):\n",
    "                    maxReward = reward\n",
    "                    Policy[i, j, k] = np.array([mv1, mv2, mv3])\n",
    "            V[i, j, k] = maxReward \n",
    "\n",
    "        if(normInfinity(V, oldV) <= 0.1):\n",
    "            print(\"Converged in {} iteration\".format(iter1 + 2))\n",
    "            break\n",
    "        print(\"Time for 1 iter = \",time.time() - a)\n",
    "    return V, Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "Size = (ml1, ml2, ml3)\n",
    "Value = np.zeros(Size)\n",
    "Policy = np.zeros(Size + tuple([3]))\n",
    "a = time.time()\n",
    "V, P = ValueIteration(Value, Policy)\n",
    "print(\"Time Taken = \",time.time() - a)\n",
    "np.savetxt(\"Value2.txt\", np.ravel(V).reshape(ml1*ml2, ml3), fmt = \"%.2f\", header = 'values')\n",
    "np.savetxt(\"Policy1.txt\", np.ravel(P).reshape(ml1*ml2*ml3, 3), fmt = \"%i\")\n",
    "print(\"Value2.txt Saved\")\n",
    "print(\"Policy2.txt Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
